{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## premier test avec pytorch et premier hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "True\n",
      "12.6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.version.cuda)  # Check CUDA version\n",
    "print(torch.backends.cudnn.enabled)  # Should be True if cuDNN is available\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(torch.__version__)  # Should match your installed CUDA version\n",
    "print(torch.version.cuda)  # Should match NVIDIA drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "tokenizer.pad_token =  tokenizer.eos_token\n",
    "#tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_hook(module, input, output):\n",
    "    print(f'{module} : output')\n",
    "    print(output.shape)\n",
    "    print(output)\n",
    "def input_hook(module, input, output):\n",
    "    print(f'{module} : input')\n",
    "    print(input)\n",
    "\n",
    "def naive_noise_hook(module,input,output): #a rajouter : le fait de selectionner uniquement les bon token, et la bonne variance pour le bruit\n",
    "    noise = torch.randn_like(output)#*sqrt(3*variance)\n",
    "    return output+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook pour observer ce qu'il se passe dedans\n",
    "hook1 = model.transformer.wte.register_forward_hook(input_hook)\n",
    "hook2 = model.transformer.wte.register_forward_hook(output_hook)\n",
    "hook3 = model.transformer.wpe.register_forward_hook(input_hook)\n",
    "hook4 = model.transformer.wpe.register_forward_hook(output_hook)\n",
    "hook5 = model.transformer.drop.register_forward_hook(input_hook)\n",
    "hook6 = model.transformer.drop.register_forward_hook(output_hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hook pour ajouter du bruit\n",
    "noise_hook1 = model.transformer.drop.register_forward_hook(naive_noise_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`GPT2SdpaAttention` is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(50257, 768) : input\n",
      "(tensor([[16353,   856,    13,   785,   318,  6898,   416]], device='cuda:0'),)\n",
      "Embedding(50257, 768) : output\n",
      "torch.Size([1, 7, 768])\n",
      "tensor([[[ 0.1093, -0.0582,  0.1388,  ...,  0.2905,  0.1858, -0.1798],\n",
      "         [-0.1931,  0.1698,  0.1210,  ...,  0.1461, -0.2375, -0.0535],\n",
      "         [ 0.0466, -0.0113,  0.0283,  ..., -0.0735,  0.0496,  0.0963],\n",
      "         ...,\n",
      "         [-0.0097,  0.0101,  0.0556,  ...,  0.1145, -0.0380, -0.0254],\n",
      "         [ 0.0211,  0.1182,  0.0958,  ..., -0.1856, -0.1424,  0.1010],\n",
      "         [ 0.0040,  0.0265,  0.0364,  ..., -0.0668, -0.0158,  0.1041]]],\n",
      "       device='cuda:0')\n",
      "Embedding(1024, 768) : input\n",
      "(tensor([[0, 1, 2, 3, 4, 5, 6]], device='cuda:0'),)\n",
      "Embedding(1024, 768) : output\n",
      "torch.Size([1, 7, 768])\n",
      "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
      "           2.8267e-02,  5.4490e-02],\n",
      "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
      "           1.0172e-02, -1.5573e-04],\n",
      "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
      "           1.9325e-02, -2.1424e-02],\n",
      "         ...,\n",
      "         [ 7.6374e-03, -2.5090e-02,  1.2696e-01,  ...,  8.4643e-03,\n",
      "           9.8542e-03, -7.0117e-03],\n",
      "         [ 9.6023e-03, -3.3885e-02,  1.3123e-01,  ...,  5.8940e-03,\n",
      "           7.1222e-03, -7.4742e-03],\n",
      "         [ 2.6788e-03, -2.0530e-02,  1.1961e-01,  ...,  2.4907e-03,\n",
      "           3.7071e-03, -2.5584e-03]]], device='cuda:0')\n",
      "Dropout(p=0.1, inplace=False) : input\n",
      "(tensor([[[ 0.0905, -0.2557,  0.1428,  ...,  0.2474,  0.2141, -0.1253],\n",
      "         [-0.1692,  0.1160,  0.0261,  ...,  0.1803, -0.2274, -0.0537],\n",
      "         [ 0.0509, -0.0961,  0.0828,  ..., -0.0538,  0.0689,  0.0749],\n",
      "         ...,\n",
      "         [-0.0021, -0.0150,  0.1825,  ...,  0.1230, -0.0282, -0.0324],\n",
      "         [ 0.0307,  0.0843,  0.2270,  ..., -0.1797, -0.1352,  0.0935],\n",
      "         [ 0.0066,  0.0060,  0.1560,  ..., -0.0644, -0.0121,  0.1015]]],\n",
      "       device='cuda:0'),)\n",
      "Dropout(p=0.1, inplace=False) : output\n",
      "torch.Size([1, 7, 768])\n",
      "tensor([[[ 0.0905, -0.2557,  0.1428,  ...,  0.2474,  0.2141, -0.1253],\n",
      "         [-0.1692,  0.1160,  0.0261,  ...,  0.1803, -0.2274, -0.0537],\n",
      "         [ 0.0509, -0.0961,  0.0828,  ..., -0.0538,  0.0689,  0.0749],\n",
      "         ...,\n",
      "         [-0.0021, -0.0150,  0.1825,  ...,  0.1230, -0.0282, -0.0324],\n",
      "         [ 0.0307,  0.0843,  0.2270,  ..., -0.1797, -0.1352,  0.0935],\n",
      "         [ 0.0066,  0.0060,  0.1560,  ..., -0.0644, -0.0121,  0.1015]]],\n",
      "       device='cuda:0')\n",
      " the: 0.0198\n",
      " of: 0.0146\n",
      " a: 0.0132\n",
      " are: 0.0125\n"
     ]
    }
   ],
   "source": [
    "# deuxième run avec bruit\n",
    "input= tokenizer(\"Audible.com is owned by\", return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input, labels = input.input_ids, output_hidden_states = True, output_attentions =True)\n",
    "probs = F.softmax(outputs.logits[0, -1, :], dim=-1)\n",
    "top_probs, top_indices = torch.topk(probs, 4)\n",
    "\n",
    "# les probas des mots\n",
    "top_words = [tokenizer.decode([idx]) for idx in top_indices]\n",
    "for word, prob in zip(top_words, top_probs):\n",
    "    print(f\"{word}: {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook1.remove()\n",
    "hook2.remove()\n",
    "hook3.remove()\n",
    "hook4.remove()\n",
    "hook5.remove()\n",
    "hook6.remove()\n",
    "noise_hook1.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dit si un token se réfère au sujet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://rome.baulab.info/data/dsets/known_1000.json'\n",
    "response = requests.get(url) \n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [dict['prompt'] for dict in data]\n",
    "subjects = [dict['subject'] for dict in data]\n",
    "input= tokenizer(prompts, return_tensors=\"pt\", padding= True, return_offsets_mapping= True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 0,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = []\n",
    "for j, prompt in enumerate(prompts):\n",
    "    map = torch.zeros_like(input.input_ids[j], dtype=torch.int)\n",
    "    for i,t in enumerate(input.offset_mapping[j]):\n",
    "        \n",
    "        if (prompts[j].find(subjects[j])-1<=t[0]) and (t[1]<=prompts[j].find(subjects[j])+len(subjects[j])):\n",
    "            map[i] = 1\n",
    "    mask.append(map)\n",
    "masks_tensor = torch.stack(mask)\n",
    "masks_tensor = torch.logical_and(masks_tensor, input.attention_mask).int()\n",
    "masks_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour le prompt i, masks-tensor[i] donne un mask qui dit si oui ou non les tokens se réfèrent au sujet (1 si c'est le cas, 0 sinon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rajoute le bruit sur les bons tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_hook(module,input,output):\n",
    "    std_dev_all = torch.std(output.flatten())\n",
    "    noise = torch.randn_like(output)*3*std_dev_all\n",
    "    noisy_output = output + noise * masks_tensor.unsqueeze(-1).float()\n",
    "    return noisy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui sert à obtenir le logits du dernier non-padding token\n",
    "def last_non_padding_token_logits(logits, attention_mask):\n",
    "    # For each input, find the last non-padding token\n",
    "    last_non_padding_logits = []\n",
    "    \n",
    "    for i in range(logits.size(0)):  # Loop over each prompt in the batch\n",
    "        # Find the last non-padding token position\n",
    "        non_padding_positions = (attention_mask[i] == 1).nonzero(as_tuple=True)[0]\n",
    "        last_non_padding_token_index = non_padding_positions[-1]\n",
    "        \n",
    "        # Get the logits of the last non-padding token\n",
    "        last_non_padding_logits.append(logits[i, last_non_padding_token_index])\n",
    "    last_non_padding_logits = torch.stack(last_non_padding_logits)\n",
    "    return last_non_padding_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparations des prompts en batchs pour optimiser les performances GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batchedInput = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]\n",
    "logits_utile_batched_no_noise = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sans le bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n",
      "in progress\n"
     ]
    }
   ],
   "source": [
    "for batch in batchedInput:\n",
    "    print(\"in progress\")\n",
    "    input= tokenizer(batch, return_tensors=\"pt\", padding= True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits_utile_batched_no_noise.append(last_non_padding_token_logits(model(**input, labels = input.input_ids, output_hidden_states = True, output_attentions =True).logits,input.attention_mask))\n",
    "    del input\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avec le bruit cette fois : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_noise_hook = model.transformer.drop.register_forward_hook(noise_hook)\n",
    "logits_utile_batched_with_noise=[]\n",
    "\n",
    "for batch in batchedInput:\n",
    "    input= tokenizer(batch, return_tensors=\"pt\", padding= True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits_utile_batched_with_noise.append(last_non_padding_token_logits(model(**input, labels = input.input_ids, output_hidden_states = True, output_attentions =True).logits,input.attention_mask))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the: 0.5994\n",
      " Europe: 0.0154\n",
      " Africa: 0.0143\n",
      " a: 0.0143\n"
     ]
    }
   ],
   "source": [
    "#logits_utile = last_non_padding_token_logits(outputs.logits,input.attention_mask)\n",
    "logits_utile= torch.cat(logits_utile_batched_with_noise)\n",
    "#Le mot prédit pour le 1er prompt avec le noise\n",
    "probs = F.softmax(logits_utile, dim=-1)\n",
    "top_probs, top_indices = torch.topk(probs[0], 4)\n",
    "\n",
    "# les probas des mots\n",
    "top_words = [tokenizer.decode([idx]) for idx in top_indices]\n",
    "for word, prob in zip(top_words, top_probs):\n",
    "    print(f\"{word}: {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_noise_hook.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectified corrupted run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
